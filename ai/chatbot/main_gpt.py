from rag_service.flows.diet_recommend import diet_recommend_flow
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from openai import AsyncOpenAI
import os
import re
from pathlib import Path
from typing import Optional, Dict, Any, List
from dotenv import load_dotenv
import sys
import logging

BASE_DIR = Path(__file__).resolve().parent.parent
ENV_PATH = BASE_DIR / ".env"
load_dotenv(dotenv_path=ENV_PATH)

# Logging ì„¤ì • (DEBUGë¡œ ê°•ì œ ì„¤ì •)
logging.basicConfig(level=logging.DEBUG,
                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# RAG Service import
sys.path.insert(0, str(BASE_DIR))

app = FastAPI(
    title="YumCoach Chatbot API",
    version="1.0.0"
)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
if not OPENAI_API_KEY:
    raise RuntimeError(
        "OPENAI_API_KEY is missing. Set it in .env or environment.")

client = AsyncOpenAI(
    base_url="https://gms.ssafy.io/gmsapi/api.openai.com/v1",
    api_key=OPENAI_API_KEY
)

# í•´ì‹œíƒœê·¸ -> í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë§¤í•‘
HASHTAG_TO_FILE = {
    "#ì£¼ê°„ë¦¬í¬íŠ¸": "weekly_report.txt",
    "#ì¼ì¼ë¦¬í¬íŠ¸": "daily_report.txt",
    "#ì‹ë‹¨": "diet.txt",
    "#ìƒë‹´": "counsel.txt"
}


def load_prompt(filename: str) -> str:
    """í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ"""
    prompt_path = Path(__file__).parent / "prompts" / filename
    try:
        with open(prompt_path, 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        print(f"Warning: {filename} not found, using default")
        return load_prompt("default.txt")


def extract_hashtag(message: str) -> tuple[Optional[str], str]:
    """ë©”ì‹œì§€ì—ì„œ í•´ì‹œíƒœê·¸ ì¶”ì¶œ (ìœ„ì¹˜ ë¬´ê´€)"""
    pattern = r'#(ì£¼ê°„ë¦¬í¬íŠ¸|ì¼ì¼ë¦¬í¬íŠ¸|ì‹ë‹¨|ìƒë‹´)'
    match = re.search(pattern, message)

    if match:
        hashtag = match.group(0)
        clean_message = re.sub(pattern, '', message).strip()
        return hashtag, clean_message

    return None, message


def format_health_status(user_profile: dict) -> str:
    """ê±´ê°• ìƒíƒœë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    conditions = []

    # 0=ì—†ìŒ, 1=ìˆìŒ
    if user_profile.get('diabetes') == 1:
        conditions.append('ë‹¹ë‡¨')
    if user_profile.get('high_blood_pressure') == 1:
        conditions.append('ê³ í˜ˆì••')
    if user_profile.get('hyperlipidemia') == 1:
        conditions.append('ê³ ì§€í˜ˆì¦')
    if user_profile.get('kidney_disease') == 1:
        conditions.append('ì‹ ì¥ì§ˆí™˜')

    if not conditions:
        return 'íŠ¹ë³„í•œ ì§ˆí™˜ ì—†ìŒ'

    return ', '.join(conditions) + ' ë³´ìœ '


def build_system_prompt(
    hashtag: Optional[str],
    hashtag: Optional[str],
    user_profile: Optional[dict] = None,
    report_data: Optional[dict] = None
) -> str:
    """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    # í•´ì‹œíƒœê·¸ì— ë§ëŠ” í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ
    if hashtag and hashtag in HASHTAG_TO_FILE:
        base_prompt = load_prompt(HASHTAG_TO_FILE[hashtag])
    else:
        base_prompt = load_prompt("default.txt")

    # ì‚¬ìš©ì í”„ë¡œí•„ ì •ë³´ ì£¼ì…
    if user_profile:
        name = user_profile.get('name', 'ì‚¬ìš©ì')
        height = user_profile.get('height', 'ì•Œ ìˆ˜ ì—†ìŒ')
        weight = user_profile.get('weight', 'ì•Œ ìˆ˜ ì—†ìŒ')
        health_status = format_health_status(user_profile)

        # í…œí”Œë¦¿ ì¹˜í™˜
        try:
            base_prompt = base_prompt.format(
                name=name,
                height=height,
                weight=weight,
                health_status=health_status
            )
        except KeyError:
            # í…œí”Œë¦¿ ë³€ìˆ˜ê°€ ì—†ëŠ” ê²½ìš° (ê¸°ë³¸ í”„ë¡¬í”„íŠ¸)
            pass

    # TODO: ë¦¬í¬íŠ¸ ë°ì´í„° ì£¼ì…

    return base_prompt


class ChatRequest(BaseModel):
    message: str
    user_id: str = None
    user: Dict[str, Any] = None
    user_health: Dict[str, Any] = None
    user_profile: dict = None
    dietary_restrictions: List[str] = None
    today_report: Dict[str, Any] = None
    report_data: dict = None
    user_role: str = None  # "BASIC", "ADVANCED" ë“±


class ChatResponse(BaseModel):
    reply: str
    detected_hashtag: str = None


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    # ì‹ë‹¨ ì½”ì¹­ ì±—ë´‡ API


    ## í˜„ì¬ ì§€ì› ê¸°ëŠ¥:
    - #ì‹ë‹¨: ì‹ë‹¨ ì¶”ì²œ (ë¦¬í¬íŠ¸ ê¸°ë°˜, ADVANCED ìœ ì €ë§Œ ì‚¬ìš© ê°€ëŠ¥)
    - #ìƒë‹´: ì‹ë‹¨ ê´€ë ¨ ê³ ë¯¼ ìƒë‹´ (ë¦¬í¬íŠ¸ ë¶ˆí•„ìš”)
    - #ì¼ì¼ë¦¬í¬íŠ¸: ì¼ì¼ ì‹ë‹¨ ë¶„ì„ (ë¦¬í¬íŠ¸ í•„ìš”, í˜„ì¬ ë¯¸êµ¬í˜„)
    - #ì£¼ê°„ë¦¬í¬íŠ¸: ì£¼ê°„ ì‹ë‹¨ ë¶„ì„ (ë¦¬í¬íŠ¸ í•„ìš”, í˜„ì¬ ë¯¸êµ¬í˜„)


    ## user_profile ì˜ˆì‹œ:
    ```json
    {
        "name": "í…ŒìŠ¤íŠ¸ ìœ ì €",
        "height": 175,
        "weight": 70,
        "diabetes": 0,
        "high_blood_pressure": 0,
        "hyperlipidemia": 0,
        "kidney_disease": 0
    }
    ```

    ## ì‚¬ìš© ì˜ˆì‹œ: #ì‹ë‹¨ ì¶”ì²œ (ADVANCED ìœ ì €)
    ```json
    {
        "message": "#ì‹ë‹¨ ì§€ê¸ˆê¹Œì§€ì˜ ì‹ë‹¨ì„ ê¸°ë°˜ìœ¼ë¡œ ì €ë…ì— ë­˜ ë¨¹ì„ì§€ ì¶”ì²œí•´ì¤˜",
        "user_id": "2",
        "user_role": "ADVANCED",
        "user": {
            "name": "í™ê¸¸ë™",
            "age": 30
        },
        "user_health": {
            "height": 175,
            "weight": 70,
            "activity_level": "MEDIUM"
        },
        "dietary_restrictions": ["í•´ì‚°ë¬¼", "ê²¬ê³¼ë¥˜"],
        "today_report": {
            "type": "DAILY",
            "totalCalories": 1800,
            "proteinG": 55,
            "carbG": 200,
            "fatG": 50,
            "mealCount": 3,
            "meals": [...]
        }
    }
    ```
    """
    try:
        # í•´ì‹œíƒœê·¸ ì¶”ì¶œ
        logger.debug(f"ğŸ“¥ /chat ìš”ì²­ ìˆ˜ì‹ : message={request.message[:50]}...")
        hashtag, clean_message = extract_hashtag(request.message)
        logger.debug(f"   ì¶”ì¶œëœ hashtag: {hashtag}")

        # ===== #ì‹ë‹¨ (RAG ê¸°ë°˜ ì¶”ì²œ) =====
        if hashtag == "#ì‹ë‹¨":
            logger.info(
                f"ğŸ¯ #ì‹ë‹¨ ìš”ì²­ ê°ì§€. ì‚¬ìš©ì: {request.user.get('name') if request.user else 'unknown'}")
            # Role ì²´í¬
            user_role = request.user_role or ""
            if user_role != "ADVANCED":
                raise HTTPException(
                    status_code=403,
                    detail=f"ì´ ê¸°ëŠ¥ì€ ADVANCED ìœ ì €ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤. í˜„ì¬ ì—­í• : {user_role or 'UNKNOWN'}"
                )

            # í•„ìˆ˜ í•„ë“œ ì²´í¬
            if not request.today_report:
                raise HTTPException(
                    status_code=400,
                    detail="ì˜¤ëŠ˜ì˜ ë¦¬í¬íŠ¸ ë°ì´í„°(today_report)ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                )

            if not request.user or not request.user.get("name"):
                raise HTTPException(
                    status_code=400,
                    detail="ì‚¬ìš©ì ì •ë³´(user)ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                )

            if not request.user_health:
                raise HTTPException(
                    status_code=400,
                    detail="ì‚¬ìš©ì ê±´ê°• ì •ë³´(user_health)ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                )

            # RAG í”Œë¡œìš° í˜¸ì¶œ
            logger.info(f"ğŸš€ diet_recommend_flow.recommend() í˜¸ì¶œ...")
            result = await diet_recommend_flow.recommend(
                message=clean_message,
                user_id=request.user_id or "unknown",
                user=request.user,
                user_health=request.user_health,
                dietary_restrictions=request.dietary_restrictions or [],
                today_report=request.today_report,
                meal_type="dinner"  # ê¸°ë³¸ê°’
            )
            logger.info(
                f"âœ… recommend() ì™„ë£Œ. result íƒ€ì…: {type(result)}, keys: {result.keys() if isinstance(result, dict) else 'N/A'}")

            import json as _json
            # í”„ë¡¬í”„íŠ¸ ìš”êµ¬ í˜•ì‹(JSON)ë§Œ replyì— ë‹´ì•„ ë°˜í™˜
            llm_reply_obj = {
                "summary": result.get("summary", ""),
                "meal_suggestion": result.get("meal_suggestion", ""),
                "tips": result.get("tips", []),
            }

            return ChatResponse(
                reply=_json.dumps(llm_reply_obj, ensure_ascii=False),
                detected_hashtag=hashtag
            )

        # ===== ê¸°ì¡´ ë¡œì§ (ì¼ë°˜ ì±—ë´‡) =====
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = build_system_prompt(
            hashtag,
            request.user_profile or request.user,
            request.report_data
        )

        # ë©”ì‹œì§€ êµ¬ì„±
        messages = [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": clean_message}
        ]

        # API í˜¸ì¶œ
        stream = await client.chat.completions.create(
            model='gpt-5-nano',
            messages=messages,
            stream=False,
        )

        return ChatResponse(
            reply=stream.choices[0].message.content,
            detected_hashtag=hashtag
        )

    except HTTPException:
        raise
    except Exception as e:
        import traceback
        traceback.print_exc()
        raise HTTPException(status_code=500, detail=str(e))

# ì‹¤í–‰: uvicorn main:app --host 0.0.0.0 --port 8001
