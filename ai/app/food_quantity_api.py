from flask import Flask, request, jsonify
import torch
import torch.nn.functional as F
from torch.autograd import Variable
from torchvision import transforms
from PIL import Image
import numpy as np
import os
import io
import traceback
import time

app = Flask(__name__)


class FoodQuantityPredictor:
    def __init__(self, model_path, device='cpu'):
        """
        ìŒì‹ ì–‘ ë¶„ë¥˜ ëª¨ë¸ ì´ˆê¸°í™”

        Args:
            model_path: í•™ìŠµëœ ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ ê²½ë¡œ
            device: 'cuda' ë˜ëŠ” 'cpu'
        """
        self.device = torch.device(
            device if torch.cuda.is_available() else 'cpu')
        print(f"ğŸš€ Using device: {self.device}")

        # ëª¨ë¸ ë¡œë“œ
        self.model, self.class_to_idx = self.load_checkpoint(model_path)
        self.model = self.model.to(self.device)
        self.model.eval()

        # í´ë˜ìŠ¤ ë§¤í•‘
        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}
        self.class_names = ['Q1', 'Q2', 'Q3', 'Q4', 'Q5']

        print("âœ… ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        print(f"ğŸ“Š ì§€ì› í´ë˜ìŠ¤: {self.class_names}")

    def load_checkpoint(self, filepath):
        """ì²´í¬í¬ì¸íŠ¸ì—ì„œ ëª¨ë¸ ë¡œë“œ"""
        try:
            print(f"ğŸ“‚ ëª¨ë¸ ë¡œë”© ì¤‘: {filepath}")

            checkpoint = torch.load(
                filepath, map_location=self.device, weights_only=False)

            # ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° í™•ì¸ ë° ì²˜ë¦¬
            if 'model_ft' in checkpoint:
                model = checkpoint['model_ft']
                model.load_state_dict(checkpoint['state_dict'], strict=False)
                class_to_idx = checkpoint.get(
                    'class_to_idx', {f'Q{i}': i-1 for i in range(1, 6)})
            else:
                # ë‹¤ë¥¸ ì²´í¬í¬ì¸íŠ¸ êµ¬ì¡° ì²˜ë¦¬
                model = checkpoint.get('model', checkpoint)
                class_to_idx = checkpoint.get(
                    'class_to_idx', {f'Q{i}': i-1 for i in range(1, 6)})

            # ì¶”ë¡  ëª¨ë“œ ì„¤ì •
            for param in model.parameters():
                param.requires_grad = False

            return model, class_to_idx

        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë”© ì˜¤ë¥˜: {e}")
            if 'checkpoint' in locals():
                print(f"ğŸ” ì²´í¬í¬ì¸íŠ¸ í‚¤: {list(checkpoint.keys())}")
            raise

    def process_image(self, image):
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ê¸°ì¡´ ìŠ¤í¬ë¦½íŠ¸ì™€ ë™ì¼í•œ ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸)
        """
        preprocess = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std=[0.229, 0.224, 0.225])
        ])

        # RGB ë³€í™˜ (RGBAë‚˜ ë‹¤ë¥¸ ëª¨ë“œ ì²˜ë¦¬)
        if image.mode != 'RGB':
            image = image.convert('RGB')

        return preprocess(image)

    def predict(self, image_input, topk=5):
        """
        ë‹¨ì¼ ì´ë¯¸ì§€ì—ì„œ ìŒì‹ ì–‘ ì˜ˆì¸¡

        Args:
            image_input: PIL Image ê°ì²´, íŒŒì¼ ê²½ë¡œ, ë˜ëŠ” ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼
            topk: ìƒìœ„ kê°œ ì˜ˆì¸¡ ê²°ê³¼ ë°˜í™˜

        Returns:
            dict: ì˜ˆì¸¡ ê²°ê³¼
        """
        try:
            # ì…ë ¥ íƒ€ì…ì— ë”°ë¥¸ ì´ë¯¸ì§€ ë¡œë“œ
            if isinstance(image_input, str):
                # íŒŒì¼ ê²½ë¡œ
                image = Image.open(image_input)
            elif hasattr(image_input, 'read'):
                # íŒŒì¼ ê°ì²´ (Flask FileStorage ë“±)
                image = Image.open(image_input)
            elif isinstance(image_input, bytes):
                # ë°”ì´íŠ¸ ìŠ¤íŠ¸ë¦¼
                image = Image.open(io.BytesIO(image_input))
            else:
                # PIL Image ê°ì²´
                image = image_input

            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            img_tensor = self.process_image(image)
            img_tensor = img_tensor.unsqueeze(0)  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€

            # ì˜ˆì¸¡ ìˆ˜í–‰ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´ torch.no_grad() ì‚¬ìš©)
            with torch.no_grad():
                inputs = img_tensor.to(self.device)
                logits = self.model(inputs)
                probabilities = F.softmax(logits, dim=1)

                # Top-k ê²°ê³¼ ì¶”ì¶œ
                topk_probs, topk_indices = probabilities.cpu().topk(topk)
                topk_probs = topk_probs.squeeze().tolist()
                topk_indices = topk_indices.squeeze().tolist()

                # ë‹¨ì¼ ì˜ˆì¸¡ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                if not isinstance(topk_probs, list):
                    topk_probs = [topk_probs]
                    topk_indices = [topk_indices]

            # ê²°ê³¼ êµ¬ì„±
            predictions = []
            for prob, idx in zip(topk_probs, topk_indices):
                class_name = self.class_names[idx] if idx < len(
                    self.class_names) else f'Q{idx+1}'
                predictions.append({
                    'class': class_name,
                    'probability': float(prob),
                    'percentage': f"{float(prob) * 100:.2f}%"
                })

            # ìµœìƒìœ„ ì˜ˆì¸¡
            top_prediction = predictions[0]

            return {
                'success': True,
                'predicted_quantity': top_prediction['class'],
                'confidence': top_prediction['probability'],
                'confidence_percentage': top_prediction['percentage'],
                'all_predictions': predictions
            }

        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'traceback': traceback.format_exc()
            }


# ì „ì—­ ì˜ˆì¸¡ê¸° ë³€ìˆ˜
predictor = None


def initialize_model(model_path='./weights/new_opencv_ckpt_b84_e200.pth'):
    """ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ì´ˆê¸°í™”"""
    global predictor

    try:
        device_type = 'cuda' if torch.cuda.is_available() else 'cpu'
        print(f"ğŸ”§ ëª¨ë¸ ì´ˆê¸°í™” ì¤‘... (ë””ë°”ì´ìŠ¤: {device_type})")

        predictor = FoodQuantityPredictor(model_path, device=device_type)

        print("=" * 60)
        print("ğŸ‰ ìŒì‹ ì–‘ ì˜ˆì¸¡ API ì„œë²„ ì¤€ë¹„ ì™„ë£Œ!")
        print("=" * 60)

        return True

    except Exception as e:
        print(f"ğŸ’¥ ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        traceback.print_exc()
        return False

# Flask ë¼ìš°íŠ¸ ì •ì˜


@app.route('/', methods=['GET'])
def home():
    """API ì •ë³´ í˜ì´ì§€"""
    return jsonify({
        'service': 'Food Quantity Prediction API',
        'version': '1.0',
        'status': 'running' if predictor else 'model not loaded',
        'endpoints': {
            '/predict': 'POST - ì´ë¯¸ì§€ íŒŒì¼ ì—…ë¡œë“œë¡œ ìŒì‹ ì–‘ ì˜ˆì¸¡',
            '/health': 'GET - ì„œë²„ ìƒíƒœ í™•ì¸'
        },
        'classes': {
            'Q1': 'ë§¤ìš° ì ì€ ì–‘',
            'Q2': 'ì ì€ ì–‘',
            'Q3': 'ë³´í†µ ì–‘',
            'Q4': 'ë§ì€ ì–‘',
            'Q5': 'ë§¤ìš° ë§ì€ ì–‘'
        }
    })


@app.route('/health', methods=['GET'])
def health_check():
    """ì„œë²„ ìƒíƒœ í™•ì¸"""
    if predictor:
        return jsonify({
            'status': 'healthy',
            'model_loaded': True,
            'device': str(predictor.device),
            'timestamp': time.time()
        })
    else:
        return jsonify({
            'status': 'unhealthy',
            'model_loaded': False,
            'error': 'Model not initialized'
        }), 500


@app.route('/predict', methods=['POST'])
def predict_quantity():
    """
    ì´ë¯¸ì§€ë¥¼ ë°›ì•„ ìŒì‹ ì–‘ ì˜ˆì¸¡

    Form Data:
        - image: ì´ë¯¸ì§€ íŒŒì¼
        - topk: (ì„ íƒ) ìƒìœ„ kê°œ ê²°ê³¼ ë°˜í™˜ (ê¸°ë³¸ê°’: 5)

    Returns:
        JSON: ì˜ˆì¸¡ ê²°ê³¼
    """
    global predictor

    if predictor is None:
        return jsonify({
            'success': False,
            'error': 'Model not initialized'
        }), 500

    # ì´ë¯¸ì§€ íŒŒì¼ í™•ì¸
    if 'image' not in request.files:
        return jsonify({
            'success': False,
            'error': 'No image file provided. Please upload with key "image"'
        }), 400

    image_file = request.files['image']

    if image_file.filename == '':
        return jsonify({
            'success': False,
            'error': 'Empty filename'
        }), 400

    # topk íŒŒë¼ë¯¸í„°
    topk = int(request.form.get('topk', 5))

    try:
        start_time = time.time()

        # ì˜ˆì¸¡ ìˆ˜í–‰
        result = predictor.predict(image_file, topk=topk)

        # ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
        result['processing_time'] = f"{(time.time() - start_time):.3f}s"

        return jsonify(result)

    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e),
            'traceback': traceback.format_exc()
        }), 500


if __name__ == '__main__':
    # ëª¨ë¸ ê²½ë¡œ í™•ì¸
    model_path = './weights/new_opencv_ckpt_b84_e200.pth'

    if not os.path.exists(model_path):
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        print("ğŸ’¡ ë‹¤ìŒì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
        print("   1. weights í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€")
        print("   2. new_opencv_ckpt_b84_e200.pth íŒŒì¼ì´ ìˆëŠ”ì§€")
        exit(1)

    # ëª¨ë¸ ì´ˆê¸°í™”
    if not initialize_model(model_path):
        print("ğŸ’¥ ì„œë²„ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        exit(1)

    # Flask ì„œë²„ ì‹¤í–‰
    print("ğŸŒ Flask ì„œë²„ ì‹œì‘ ì¤‘...")
    app.run(host='0.0.0.0', port=5001, debug=False)
