# food_classification_api.py
import traceback
from typing import Union, Dict
import time
import io
from PIL import Image
import numpy as np
import cv2
import torch
import sys
import os

# =============================================================================
# ğŸ”¥ ì¤‘ìš”: ë‹¤ë¥¸ importë³´ë‹¤ ë¨¼ì € ê²½ë¡œ ì„¤ì •
# =============================================================================


def setup_yolo_paths():
    """YOLOv3 ëª¨ë“ˆ ê²½ë¡œë¥¼ ìë™ìœ¼ë¡œ ì°¾ì•„ì„œ sys.pathì— ì¶”ê°€"""
    current_dir = os.path.dirname(os.path.abspath(__file__))

    # ê°€ëŠ¥í•œ YOLOv3 ê²½ë¡œë“¤ (ìš°ì„ ìˆœìœ„ ìˆœ)
    possible_paths = [
        '/app/yolov3',  # Docker í™˜ê²½
        os.path.join(current_dir, 'yolov3'),  # app/yolov3/
        os.path.join(os.path.dirname(current_dir), 'yolov3'),  # ../yolov3/
        os.path.join(current_dir, '..', 'yolov3'),  # ìƒìœ„ í´ë”ì˜ yolov3
    ]

    for path in possible_paths:
        if os.path.exists(path) and os.path.exists(os.path.join(path, 'models.py')):
            if path not in sys.path:
                sys.path.insert(0, path)
            print(f"âœ… YOLOv3 ê²½ë¡œ ì„¤ì •: {path}")
            return path

    # ëª¨ë“  ê²½ë¡œì—ì„œ ì°¾ì§€ ëª»í•œ ê²½ìš°
    raise RuntimeError(f"âŒ YOLOv3 í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™•ì¸í•œ ê²½ë¡œ: {possible_paths}")


# ê²½ë¡œ ì„¤ì • ì‹¤í–‰
yolo_path = setup_yolo_paths()

# =============================================================================
# ì´ì œ YOLOv3 ëª¨ë“ˆë“¤ì„ importí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
# =============================================================================

# YOLOv3 ëª¨ë“ˆ import
try:
    from models import Darknet
    from utils.datasets import letterbox
    from utils.utils import non_max_suppression, scale_coords, load_classes
    from utils import torch_utils
    print("âœ… YOLOv3 ëª¨ë“ˆ import ì„±ê³µ!")
except ImportError as e:
    print(f"âŒ YOLOv3 ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
    print(f"í˜„ì¬ YOLOv3 ê²½ë¡œ: {yolo_path}")
    if os.path.exists(yolo_path):
        print(f"YOLOv3 í´ë” ë‚´ìš©: {os.listdir(yolo_path)}")
    raise


class FoodClassificationAPI:
    """YOLOv3 ê¸°ë°˜ ìŒì‹ ë¶„ë¥˜ API"""

    def __init__(
        self,
        cfg_path: str = None,
        weights_path: str = None,
        names_path: str = None,
        img_size: int = 320,
        conf_thres: float = 0.3,
        iou_thres: float = 0.5,
        device: str = ''
    ):
        # ê¸°ë³¸ ê²½ë¡œ ì„¤ì • (ë°œê²¬ëœ yolo_path ê¸°ì¤€)
        if cfg_path is None:
            cfg_path = os.path.join(yolo_path, 'cfg/yolov3-spp-403cls.cfg')
        if weights_path is None:
            weights_path = os.path.join(
                yolo_path, 'weights/best_403food_e200b150v2.pt')
        if names_path is None:
            names_path = os.path.join(yolo_path, 'data/403food.names')

        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        for path, name in [(cfg_path, 'Config'), (weights_path, 'Weights'), (names_path, 'Names')]:
            if not os.path.exists(path):
                raise FileNotFoundError(f"âŒ {name} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}")

        print(f"ğŸ“‚ Config: {cfg_path}")
        print(f"ğŸ“‚ Weights: {weights_path}")
        print(f"ğŸ“‚ Names: {names_path}")

        self.img_size = img_size
        self.conf_thres = conf_thres
        self.iou_thres = iou_thres

        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = torch_utils.select_device(device)
        print(f"ğŸš€ ë””ë°”ì´ìŠ¤: {self.device}")

        # ëª¨ë¸ ë¡œë”©
        print("ğŸ“‚ ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = Darknet(cfg_path, img_size)

        checkpoint = torch.load(
            weights_path, map_location=self.device, weights_only=False)

        self.model.load_state_dict(checkpoint['model'], strict=False)
        self.model.to(self.device).eval()

        # Half precision (GPU ì‚¬ìš© ì‹œ)
        self.half = self.device.type != 'cpu'
        if self.half:
            self.model.half()

        # í´ë˜ìŠ¤ ì´ë¦„ ë¡œë“œ
        self.names = load_classes(names_path)
        print(f"âœ… {len(self.names)}ê°œ ìŒì‹ í´ë˜ìŠ¤ ë¡œë”© ì™„ë£Œ!")

        # ì›Œë°ì—…
        print("ğŸ”¥ ëª¨ë¸ ì›Œë°ì—… ì¤‘...")
        dummy_img = torch.zeros((1, 3, img_size, img_size), device=self.device)
        with torch.no_grad():
            _ = self.model(dummy_img.half()
                           if self.half else dummy_img.float())
        print("âœ… ì¤€ë¹„ ì™„ë£Œ!")

    def preprocess_image(self, image_input) -> tuple:
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ - RGB/BGR í˜¸í™˜ì„± ê°•í™”"""
        if isinstance(image_input, str):
            # íŒŒì¼ ê²½ë¡œ - OpenCV ì‚¬ìš© (BGR)
            img0 = cv2.imread(image_input)
            if img0 is None:
                raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_input}")
        elif isinstance(image_input, Image.Image):
            # PIL Image - RGBë¥¼ BGRë¡œ ë³€í™˜
            img0 = np.array(image_input.convert('RGB'))
            img0 = cv2.cvtColor(img0, cv2.COLOR_RGB2BGR)  # ğŸ”¥ í•µì‹¬ ìˆ˜ì •
        elif isinstance(image_input, bytes):
            pil_img = Image.open(io.BytesIO(image_input))
            img0 = np.array(pil_img.convert('RGB'))
            img0 = cv2.cvtColor(img0, cv2.COLOR_RGB2BGR)  # ğŸ”¥ í•µì‹¬ ìˆ˜ì •
        elif hasattr(image_input, 'read'):
            # Flask FileStorage
            image_input.seek(0)
            pil_img = Image.open(image_input)
            img0 = np.array(pil_img.convert('RGB'))
            img0 = cv2.cvtColor(img0, cv2.COLOR_RGB2BGR)  # ğŸ”¥ í•µì‹¬ ìˆ˜ì •
        elif isinstance(image_input, np.ndarray):
            img0 = image_input
        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ íƒ€ì…: {type(image_input)}")

        # Letterbox ë¦¬ì‚¬ì´ì§• (YOLO í‘œì¤€)
        img = letterbox(img0, new_shape=self.img_size)[0]

        # HWC -> CHW (BGR ìƒíƒœ ìœ ì§€)
        img = img.transpose(2, 0, 1)
        img = np.ascontiguousarray(img)

        return img, img0

    def predict(self, image_input, return_details: bool = False) -> Dict:
        """ìŒì‹ ë¶„ë¥˜ ì˜ˆì¸¡ - ê°•í™”ëœ ë””ë²„ê¹…"""
        try:
            start_time = time.time()

            # ì „ì²˜ë¦¬
            img, img0 = self.preprocess_image(image_input)
            print(f"ğŸ“ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {img0.shape}")
            print(f"ğŸ“ ì „ì²˜ë¦¬ í›„ í¬ê¸°: {img.shape}")

            # í…ì„œ ë³€í™˜ ë° ì¶”ë¡ 
            img = torch.from_numpy(img).to(self.device)
            img = img.half() if self.half else img.float()
            img /= 255.0

            if img.ndimension() == 3:
                img = img.unsqueeze(0)

            with torch.no_grad():
                pred = self.model(img, augment=False)[0]

            if self.half:
                pred = pred.float()

            # ğŸ” Raw prediction ë¶„ì„
            if pred.shape[0] > 0:
                max_conf = torch.max(pred[..., 4]).item()
                print(f"ğŸ” ëª¨ë¸ ìµœëŒ€ ì‹ ë¢°ë„: {max_conf:.4f}")
                print(f"ğŸ” ì„¤ì •ëœ ì„ê³„ê°’: {self.conf_thres}")

                # í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ë¶„ì„
                if pred.shape[-1] > 5:
                    class_scores = pred[..., 5:]
                    max_class_conf, max_class_id = torch.max(
                        class_scores, dim=-1)

                    # ìƒìœ„ 5ê°œ í´ë˜ìŠ¤ ì¶œë ¥
                    unique_classes, counts = torch.unique(
                        max_class_id, return_counts=True)
                    print(f"\nğŸ” ì˜ˆì¸¡ëœ ìƒìœ„ í´ë˜ìŠ¤:")
                    for i in range(min(5, len(unique_classes))):
                        cls_id = int(unique_classes[i])
                        class_name = self.names[cls_id] if cls_id < len(
                            self.names) else "Unknown"
                        print(
                            f"  í´ë˜ìŠ¤ {cls_id:3d} ({class_name}): {counts[i]}ê°œ")

            # NMS ì ìš©
            pred = non_max_suppression(
                pred, self.conf_thres, self.iou_thres,
                multi_label=False, classes=None, agnostic=False
            )

            # ê²°ê³¼ ì²˜ë¦¬
            detections = []
            print(f"\nğŸ” NMS í›„ ê²€ì¶œ ê°œìˆ˜: {len(pred)}")

            for i, det in enumerate(pred):
                if det is not None and len(det):
                    print(f"ğŸ” ë°°ì¹˜ {i}: {len(det)}ê°œ ê°ì²´ ê²€ì¶œë¨")

                    det[:, :4] = scale_coords(
                        img.shape[2:], det[:, :4], img0.shape).round()

                    for j, (*xyxy, conf, cls) in enumerate(det):
                        class_id = int(cls)
                        confidence = float(conf)
                        class_name = self.names[class_id] if class_id < len(
                            self.names) else f"Unknown({class_id})"

                        print(
                            f"  [{j}] ID: {class_id:3d} | ì´ë¦„: {class_name:15s} | ì‹ ë¢°ë„: {confidence:.4f}")

                        # ğŸ”¥ í•µì‹¬: 00000000 ì œì™¸í•˜ê³  ìœ íš¨í•œ ìŒì‹ë§Œ ì¶”ê°€
                        if class_name != '00000000':
                            detections.append({
                                'class_name': class_name,
                                'confidence': confidence,
                                'confidence_percentage': f"{confidence * 100:.2f}%"
                            })

            # ê²°ê³¼ ë°˜í™˜
            detections.sort(key=lambda x: x['confidence'], reverse=True)

            if len(detections) == 0:
                print(f"\nâŒ ìœ íš¨í•œ ìŒì‹ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                print(f"ğŸ’¡ ì„ê³„ê°’ì„ {self.conf_thres}ì—ì„œ ë” ë‚®ì¶°ë³´ì„¸ìš”.")

                return {
                    'success': False,
                    'food_code': '00000000',
                    'message': 'ìŒì‹ì„ ì¸ì‹í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„ê³„ê°’ì„ ì¡°ì •í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‹œë„í•˜ì„¸ìš”.'
                }

            top_detection = detections[0]
            print(
                f"\nâœ… ìµœì¢… ì„ íƒ: {top_detection['class_name']} ({top_detection['confidence_percentage']})")

            return {
                'success': True,
                'food_code': top_detection['class_name'],
                'confidence': top_detection['confidence'],
                'confidence_percentage': top_detection['confidence_percentage']
            }

        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}")
            traceback.print_exc()
            return {
                'success': False,
                'food_code': '00000000',
                'error': str(e)
            }


# =============================================================================
# ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ë“¤
# =============================================================================
_food_classifier = None


def initModel():
    """ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ ì´ˆê¸°í™” í•¨ìˆ˜"""
    global _food_classifier

    if _food_classifier is None:
        _food_classifier = FoodClassificationAPI()

    return _food_classifier


def detect(user_img, user_seq, model=None):
    """ê¸°ì¡´ ì½”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•œ detect í•¨ìˆ˜"""
    if model is None:
        model = _food_classifier

    if model is None:
        raise RuntimeError("ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. initModel()ì„ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")

    result = model.predict(user_img)
    return result['food_code']
